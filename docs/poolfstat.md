# Poolfstat docs summary

## Input data format

Distinguishing standard allele count data from Pool-Seq data is crucial to find the appropriate f-statistics estimator.
    + _countdata_ class for allele count data
    + _pooldata_ class for read count data

Classes are automatically recogniyzed by the estimator methods=

- To get **allele count data**:
    + Use _genotreemix2countdata_ to convert [_Treemix_ outputs](treemix.md) 
    + Use _genobaypass2countdata_ to convert _BayPass_ output

```R
# using TreeMix output
# we use sim6p as a prefix for our files

# NO POSITIONAL INFORMATION FOR SNPs
sim6p.allelecount<-genotreemix2countdata(genotreemix.file = "sim6p.genotreemix.gz")

#POSITIONAL INFORMATION
positions<-read.table("sim6p.snpinfo.gz",header=TRUE,row.names=1,stringsAsFactors = FALSE)
sim6p.allelecount<-genotreemix2countdata(genotreemix.file = "sim6p.genotreemix.gz",
snp.pos=positions,verbose=FALSE)
sim6p.allelecount #display a summary of the object
```

- To get **pool count data**:
    + Use VCF data which come from (or have the same structure as the ones that come from) one of these four tools for PoolSeq variant analysis: VarScan, bcftools/SAMtools, FreeBayes and GATK (_vcf2pooldata_)
    + Use RSYNC files generated by PoPoolation (_popsync2pooldata_)
    + Use the two input files (pool haploid count and pool haploid size) needed by BayPass for its analyis (_baypass2pooldata_)
    + Use the input file required by SelEstim 

```R
# example R line to get pool count data from VCF
sim6p.readcount <-vcf2pooldata(vcf.file="sim6p.vcf.gz",poolsizes=rep(50,6))
```

Additional arguments may allow filtering the data according to the read coverage of the pool such as
_min.maf_, _min.rc_, _min.cov.per.pool_ or _max.cov.per.pool_. 

One can also subset the pooldata with the _subset_ function, using additional filters like the population of origin for the subset and the MAF threshold (minor allele frequency):

```R
# Return also SNP indexes
sim6p.subset<-pooldata.subset(sim6p.readcount,pool.index=c(2,3,6),
min.maf=0.05,return.snp.idx=TRUE,verbose=FALSE)
# View the indexes of the selected SNPs
selected.snps.idx <- as.numeric(sub("rs","",rownames(sim6p.readcount.subset@snp.info)))
head(selected.snps.idx)
```

We could pipe pool count data into DIYABC with the _pooldata2diyabc_ function (only valuable for pool data).

> ### KEY TAKE HOME MESSAGES
> - We'll use **PoolSeq data** and turn them to **VCFs** with **VarScan** or **bcftools/vcftools/SAMtools** (probably the latter solution is more established and easier to use as a pipeline)
> - We'll turn the **pool count data** into **DIYABC** input files

## Estimating $F_{ST}$

> ### Refresh! What is $F_{ST}$?
> $F_{ST}$ or **fixation index** is a parameter that estimates population differentiation due to genetic structure, i.e. the genetic patterns recognizable within individuals belongig to the same population.
>
> For the purposes of our analysis, it can be estimated with the following formula:
>
> $F_{ST} = \frac{Q_1 - Q_2}{1 - Q_2} $
>
> Where $Q_1$ is the probabily that two individuals are identical by state for a gene (i.e. they have the same gene variant without having a recent common ancestor) _within_ a population and $Q_2$ is the same probability, but _between_ populations.

The two functions _computeFST_ and _computeFST.pairwise_ implement two methods to estimate $F_{ST}$:

- A decomposition of the total variance resulting from read count frequencies or allele count in an [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance) framework (passed as _method="Anova"_)
- The unbiased estimators $\widehat{Q_1}$ and $\widehat{Q_2}$ are employed instead of the actual IBS probabilities ${Q_1}$ and ${Q_2}$ (passed as _method="Identity"_) ([what are unbiased estimators?](https://www.statlect.com/glossary/unbiased-estimator))


Let's take a look of a simple implementation of the _computeFST_ function with pool count data (by default it uses "Anova" method):

```R
sim6p.readcount.fst<-computeFST(sim6p.readcount)
sim6p.readcount.fst$FST #genome-wide Fst over all population
```

Multi-locus estimates (genome-wide and/or sliding windows) will be calculated starting from the sum of locus-specific numerators over the sum of locus-specific denominators for the different quantities (better explanation [here](./supplementary/multilocus_fst.md)). 

One could get a sense of the error in the $F_{ST}$ estimate by utilizing the Block-Jackknife estimation of the standard error (it is disabled by default, you just need to pass *nsnp.per.bjack.block = N* to set the number of consecutive SNPs that define a BJack sampling block).

You could then get:

```R
sim6p.readcount.fst<-computeFST(sim6p.readcount,nsnp.per.bjack.block = 1000,
verbose=FALSE)
#genome-wide Fst over all populations
sim6p.readcount.fst$FST 
#block-jacknife estimate of standard error
sim6p.readcount.fst$mean.fst 
#standard error of the genome-wide Fst estimate
sim6p.readcount.fst$se.fst
[1] 0.0007620463
#95% confidence interval of the estimated genome-wide Fst
sim6p.readcount.fst$mean.fst+c(-1.96,1.96)*sim6p.readcount.fst$se.f
```

## Estimating _f_-statistics ($f_2, F_{ST}, f_3, f^*_3, f_4, D$)

> ### Refresh! What are _f_-statistics?
> These statistics measure (expected) covariance in allele frequencies among sets of two (F2),
three (F3) or four (F4) populations and are formally defined as follows (denoting $p_i$ the SNP reference allele frequency in population _i_):
>
> - $F2(A; B) a \mathbb{E} [(pA - pB )^2]$
> - $F3(A; B, C) a \mathbb{E} [(pA - pB )(pA - pC)] = \frac{1}{2} (F2(A; B) + F2(A; C) + F2(B; C))$
> - $F4(A, B; C, D) a \mathbb{E} [(pA - pB ) (pC - pD )] = \frac{1}{2} (F2(A; D) + F2(B; C) + F2(A; C) + F2(B; C))$
>
> F3 and F4 are commonly used statistics in carrying out admixture tests for treeness, with F4 on quadruplets as the most used method.
>
> F*3 and D are two scaled implementations of F3 and F4, less sensitive to SNP ascertainment and thus more comparable across dataset. 

Computing _f_-statistics can be achieved with the function _compute.fstats_:

```R
# Estimation of f-statistics on Pool-Seq data (with computation of Dstat)
sim6p.readcount.fstats<-compute.fstats(sim6p.readcount,nsnp.per.bjack.block = 1000,
computeDstat = TRUE,verbose=FALSE)
```

And from here we can extract some meaningful data, like $f_2, F_{ST}$ and pairwise absolute divergence estimates:

```R
# Pool-Seq data (3 first f2)
head(sim6p.readcount.fstats@f2.values,3)

# Pool-Seq data (3 first Fst)
head(sim6p.readcount.fstats@fst.values,3)

# Pool-Seq data (3 first pairwise genetic divergence)
head(sim6p.readcount.fstats@divergence,3)
```

The $F_{ST}$ here obtained is the same obtained with the _compute.pairwiseFST_ under the "Anova" method.

When used with the default parameters, the _compute.fstats_ function outputs also pairwise $F_{ST}$ and absolute pairwise divergence which we can actually plot as heatmaps:

```R
require(ComplexHeatmap)
div.hm <- Heatmap(sim6p.readcount.fstats@pairwise.div,
cluster_rows =TRUE,cluster_columns=TRUE,name="Divergence",
show_heatmap_legend=FALSE,column_title = "Divergence (1-Q2)")
fst.hm <- Heatmap(sim6p.readcount.fstats@pairwise.fst,
cluster_rows =TRUE,cluster_columns=TRUE,name="values",
column_title = "Fst=(Q1-Q2)/(1 - Q2)")
div.hm+fst.hm
```

Which would result in something like this:

![Heatmaps](./imgs/heatmaps.png)

You can also decide to carry out a three population test with the _compute.fstats@f3.values_ and  _compute.fstats@f3star.values_ methods.

Using BJack for all these calculations produces also Z-scores, and we can for example decide to show the populations pairs that, in a three-populations test, show strong evidence of admixture (Z-score < -1.65, which means that the F3 is significantly negative):

```R
tst.sel<-sim6p.readcount.fstats@f3.values$`Z-score`< -1.65
sim6p.readcount.fstats@f3.values[tst.sel,]
```

Needless to say, we can do the same things also with F4 and D statistics for a four populations test.

You can also extract heterozygosity (i.e. the probability that an individual will be heterozygous at a given site):

```R
head(sim6p.readcount.fstats@heterozygosities,3)
```

## Visualizing _f_-statistics

You can use a simple "plot" command in R to visualize the plots, as for example with the heterozygosity:

```R
layout(matrix(1:2,1,2,byrow=T))
plot(sim6p.readcount.fstats,stat.name="heterozygosities",main="Heterozygosities (Pool-Seq)")
```

You will obtain a matrix that looks like this:

![Heterozygosity matrix](./imgs/matrix.png) 

You can do the same thing with all the other _f_-statistics, calling directly the _plot_ function on _fstats_ objects!

## Estimate admixtures with F4 ratios

Given F4 calculatations and assuming them to be correct, we can use them to calculate the relative contributions of ancestries in a two-way admixed population. We can thus calculate $\alpha$,  
which is the proportion of $P_i$ related ancestries in a $P_j$ population (assuming that $P_k$ and $P_n$ or $P_s$ are outgroups and the sixth population is $P_m$):

$\alpha = \frac{(P_k, P_n;P_j,P_m)}{(P_k, P_n;P_i,P_m)} = \frac{(P_k, P_s;P_j,P_m)}{(P_k, P_s;P_i,P_m)}$   

We can calculate this with the _compute.f4ratio_ function:

```R
# Pool-Seq data (two possible estimates)
compute.f4ratio(sim6p.readcount30X.fstats,num.quadruplet = "Pool_k,Pool_n;Pool_m,Pool_j",
den.quadruplet="Pool_k,Pool_n;Pool_m,Pool_i")
```

We then should assess the standard error, which is automatically calculated when _return.F2.blockjackknife.samples = TRUE_ and _nsnp.per.bjack.block > 0_ are set. 

```R
sim6p.readcount.fstats<-compute.fstats(sim6p.readcount30X,nsnp.per.bjack.block = 1000,
verbose=FALSE,return.F2.blockjackknife.samples = TRUE)
alpha.est=compute.f4ratio(sim6p.readcount.fstats,num.quadruplet = "Pool_k,Pool_n;Pool_m,Pool_j",
den.quadruplet="Pool_k,Pool_n;Pool_m,Pool_i")
#95% c.i. of alpha derived from the se
alpha.est[2]+c(-1.96,1.96)*alpha.est[3]
#prediction error in units of s.e.
as.numeric(abs(0.25-alpha.est[2])/alpha.est[3])
```

## Using _f_-statistics to generate admixture graphs

### 1. Generate graph parameters

There is a _graph_ object which represents admixture graphs: in order to build and plot it, you need to use the _graph.params_ class, which is, as suggested ny the name, a wrapper for the parameters of the graph.

Graph parameters cannot be easily inferred "by hand", so poolfstat comes with a _generate.graph.params_ function: 

```R
sim.graph<-rbind(c("P1","P7",""),c("P2","s1",""),c("P3","s2",""),c("P6","S",""),
c("S","s1","a"),c("S","s2","(1-a)"),c("s2","P8",""),c("s1","P7",""),
c("P4","P9",""),c("P5","P9",""),c("P7","P8",""),
c("P8","R",""),c("P9","R",""))
sim.graph.params<-generate.graph.params(sim.graph)
# To visualize edges:
sim.graph.params@edges.names
# To visualize admixture parameters:
sim.graph.params@adm.params.names
# To visualize the graph matrix:
sim.graph.params@edges.graph.matrix
```

We can now visualize the graph just by passing it to the plot() function:

```R
plot(sim.graph.params)
```

Which translates in something like this:

![Graph](./imgs/graph.png) 

> **NOTE!**
>
> The structure of a tree node (lets take for example `c("P1","P7","")`) as definied in the previous code block is the following:
> - First column is the name of the node ("P1")
> - Second column is the parent node ("P7")
> - Third column represents the admixture proportion, and it is blank if there is no admixture (""). The admixture proportion is generally expressed in terms of $\alpha$, which is simply written as "a" in the previous code block (for example here: `c("S","s2","(1-a)")`)

To improve and better "instruct" the parameters generation, it is advised to pass, along with the graph structure (_sim.graph_), also the f-statistics paramters (which can then be accessed like this: _@f2.target_):

```R
sim.graph.params<-generate.graph.params(sim.graph, fstats = sim6p.readcount.fstats)
```

Two considerations are important here:

- The number of generated parameters is $n_l + n_a - 3$, where $n_l$ is the number of leaves and $n_a$ is the number of admixture events
- The length of admixture edges (in our example: edges s1 � S, s2 � S and S � P6 connecting s1 to S; s2 to S; and S to P6 respectively) is not identifiable and can only be a joint estimate for all edges (for our example: $\zeta = \alpha^2 \times e_{s1 \leftrightarrow  S } +  (1 - \alpha)^2 \times e_{s2 \leftrightarrow  S } + e_{S \leftrightarrow  P6 }$). This problem is solved in poolfstat by nullifying the admixture edges length (for our example: $e_{s2 \leftrightarrow  S } = e_{s1 \leftrightarrow  S } = 0$): this may cause an overestimation of the divergence.

### 2. Fit an admixture graph

Let's start with a little bit of maths here. Let:

- $\hat{f}$ be the vector of length $\frac{n_l(n_l - 1)}{2}$ (where $n_l$ is the number of leaves) of the estimated F2 and F3 statistics
- $g(e;a)$ be the vector, defined as $X(a) \times e$, of the expected basis values of the f-statistics, given $e$, the vector of graph edges lengths, and $X(a)$, the incidence matrix (dependent on the structure of the graph and on the admixture rate $a$)
- $Q$ be the $\frac{n_l(n_l - 1)}{2} \times \frac{n_l(n_l - 1)}{2}$ covariance matrix estimated from the block-jackknife approach in f-statistics computation and stored under _@f.Qmat_  in the _graph.parameters_ object. 

The _graph.fit_ function, which is the one that does the heavy work in fitting the graph, is actually aimed at minimizing the score of the model by finding the best $\hat{a}$ and $\hat{e}$ parameters, and the equation goes like this: 

$S(e;a) = (\hat{f} - g(e;a))' \cdot Q^{-1}(\hat{f} - g(e;a))$

Full minimization of $S(e;a)$ is achieved by implementing the  [L-BFGS-B](https://en.wikipedia.org/wiki/Limited-memory_BFGS) via the _optim_ function in the stats package. Furthermor, if we assume that the minimization function is distributed as a normal distribution with $g(\hat{a};\hat{e})$ as mean and $Q$ as standard deviation (in symbols: $S(e;a) \sim N(g(\hat{a};\hat{e}),Q)$), we can conclude that:

$S(\hat{a};\hat{e}) = -2\log{(L)} - K$

Where $L$ is the likelihood of the fitted graph and $K = -n\log{(2\pi)} + \log{(|Q|)}$: these two parametes allow us to directly estimate the BIC (Bayesian Information Criterion).

Indeed, when comparing two graphs $G_1$ and $G_2$ with BIC equal to $BIC_1$ and $BIC_2$, $_{12}  = BIC_2  BIC_1 C 2 \log{(BF_{12})}$ where $BF_{12}$ is the Bayes Factor associated to $G1$ and $G2$ graph comparison.

In spite of the complex maths, we can easily fit a graph with the following single line of code:

```R
# Fit the graph
sim.fittedgraph<-fit.graph(sim.graph.params)
# Estimated edge lengths
sim.fittedgraph@edges.length
# Estimated admixture proportion
sim.fittedgraph@admix.prop
# Final Score
sim.fittedgraph@score
# BIC
sim.fittedgraph@bic
```
You can also get a summary of the _optim_ outputs by running:

```R
sim.fittedgraph@optim.result
```

The *admix.fact* and *edge.fact* argument of the *fit.graph* function allow to apply a multiplying factor to the printed branch lengths and admixture proportions (by default admix.fact=100, i.e., admixture proportions are printed in percentage; and edge.fact=1000, i.e. edge lengths are printed in per-thousand).

To plot the graph with our settings, we simply use the plot() function:

```R
plot(sim.fittedgraph)
```

The result will look like this:

![Graph 1](./imgs/graph_1.png)

If you want to scale the edges lenghts in drift units you just need to pass the _drift.scaling_ argument as TRUE:

```R
sim.fittedgraph.scaled<-fit.graph(sim.graph.params,drift.scaling = TRUE,verbose=FALSE)
# Estimated edge lengths
sim.fittedgraph.scaled@edges.length.scaled
# Plot the graph
plot(sim.fittedgraph.scaled)
```

The resulting plot will be:

![Graph 1](./imgs/graph_2.png)

You can additionally display the 95% CI by setting _compute.ci_ to TRUE in the _fit.graph_ function:

```R
sim.fittedgraph.scaled<-fit.graph(sim.graph.params, drift.scaling = TRUE, compute.ci = TRUE, verbose=FALSE)
```

Th procedure involves taking each parameter separately, assigning all the others to their estimated values, and considering the score difference $S_{\nu} - S^*$ (where $S^*$ is the fitted graph score associated with estimated parameter value $\nu^*$  and $S_{\nu}$ is the score associated with a parameter value $\nu \neq \nu^*$) as a likelihoiod test following a $\chi^2$ distribution with 1 DoF. The lower and upper bounds are estimated using a simple bisection method.

```R
# 95% CI for admix proportion
sim.fittedgraph.with.ci@admix.ci
# 95% CI for edge length (including drift scaled as drift.scaling=TRUE)
sim.fittedgraph.with.ci@edges.length.ci
```

### 3. Estimating the fitness of the graph

The most direct and efficient way of assessing the fitness of the graph is to compare the estimated f-statistics with the ones derived from the graph itself. In the end, everything is boiled down to the calculation of a Z-score, which is defined as: $Z = \frac{f-g}{\sigma^2_g}$, where $f$ is the graph-derived value, $g$ is the estimated one and $\sigma^2_g$ is the standard error of $g$.

In code, we can write:

```R
#Fitted basis F-stats
sim.fittedgraph.scaled@fitted.outstats
```

Which will output all the statistics with their respective Z-score: this method only works with F2 and F3 statistics, but we should also consider the other onesm which can be achieved by using the _compare.fitted.fstats_ function:

```R
sim.fitted.fstats.comp<-compare.fitted.fstats(sim6p.readcount.fstats,sim.fittedgraph)
```

The output will be equal to the previous one, with the addition of all the left-out f-statistics. 

### 4. Add a leaf to the graph

Let's say we defined the following graph:

```R
sim5p.tree<-sim.graph<-rbind(c("P1","P7",""),c("P2","P7",""),c("P3","P8",""),
c("P7","P8",""),c("P4","P9",""),c("P5","P9",""),
c("P8","R",""),c("P9","R",""))
sim5p.tree.params<-generate.graph.params(sim5p.tree)
#Note: fstats object is not necessary at this stage
plot(sim5p.tree.params)
```

And that we want to add the _P6_ leaf. We can do it with the _add.leaf_ function:

```R
add.P6<-add.leaf(sim5p.tree.params,leaf.to.add="P6",
fstats=sim6p.readcount.fstats,
verbose=FALSE,drift.scaling=TRUE)
```

This _add.P6_ object contains:

- an element named *n.graphs* corresponding to the number of tested graphs
- an element named **fitted.graph*s.list* which consists of a list of **fitted.graph** objects (indexed from 1 to
*n.graphs* and in the same order as the list graphs) containing the *fit.graph* function results for each
candidate graph
- an element named *best.*fitted.graph** which is the *fitted.graph* object associated to the candidate graph
with minimal BIC among all the *n.graphs* graphs within **fitted.graph*s.list*.
- an element named *bic* which is a vector consisting of the *n.graphs* BIC (indexed from 1 to *n.graphs* and
in the same order as the **fitted.graph*s.list* list).

Let's plot the best candidate graph:

```R
plot(add.P6$best.*fitted.graph*)
```

The comoarison to determine the best fitting graph is based on BIC, and if you want to visualize it you can use the following code:

```R
#D_BIC w.r.t. best fitted BIC
D_BIC=add.P6$bic-add.P6$best.*fitted.graph*@bic
#5 First lowest DeltaBIC (the first value of zero corresponding to the best fitted graph)
head(sort(D_BIC))
```

## Build an admixture graph from scratch

In most of the cases, we do not have/have limited information concerning the admixture status of a population, which would make it impossible or very hard to pass a graph to the *generate.graph.params* function.

This brings us to the necessity of building an admixture graph from scratch, which we will be doing in this section.

### 1. Identify and filter unadmixed populations

With the _find.tree.popset_ function, poolfstat allows to find a set of non-admixed populations, filtering out all those that show significantly negative F3 Z-scores and F4 Z-scores above a specified threshold. F3 and F4 threshold can be set with the _f3.zscore.threshold_ and _f4.zscore.threshold_: bringing the F3 threshold closer to zero or decreasing the F4 threshold may allow to decrease the number of candidate unadmixed populations chosen for the initial set.

```R
# Pool-Seq data
scaf.pops<-find.tree.popset(sim6p.readcount.fstats,verbose=FALSE)
scaf.pops$pop.sets
```

We can see what quadruplets pass the treeness test for each identified potential population set:

```R
scaf.pops$passing.quaduplets
```

And we can also take a look to the minimum and maximum absolute Z-scores:

```R
scaf.pops$Z_f4.range
```

When several sets are identified, this information may be useful to prioritize the sets of unadmixed populations
(e.g., via a minimax criterion consisting of choosing the set of populations that has the lowest maximal
absolute Z-score for its underlying quadruplets that pass the treeness test). 

### 2. Build and root a tree for candidate scaffold populations

We can use the _rooted.nj.tree_ to:

- Build an unrooted tree for the scaffold population with [Neighbor-Joining algorithm](https://en.wikipedia.org/wiki/Neighbor_joining)
- Root the tree using the criterion according to which the heterozygosity of the root R is defined as $h_R = 1 - Q^2_AB$ estimated for each population pair that is only connected through the root R (both A and B belong to the tree partition defined by R). In other words, the variation of $h_R$ in the fittest tree should be the narrowest among all the $2n_l - 3$ potential trees. 

he object returned by the *rooted.njtree.builder* function is a list consisting of:
- an element named *n.rooted.trees* corresponding to the number of possible rooted binary trees that were
evaluated
- an element named *fitted.rooted.trees.list* which consists of a list of *fitted.graph* objects (indexed from 1
to *n.rooted.trees*).
- an element named *best.rooted.tree* which corresponds to the *fitted.graph* object associated with the most
likely rooted tree (among all the *fitted.rooted.trees.list* ones) identified as the one displaying the minimal
standard deviation over the $h_R$ estimates
- an element named *root.het.est.var* consisting of a matrix of *n.rooted.trees* rows and 4 columns with: 
    + the average estimated root heterozygosity $h_R$ across all the pairs of leaves that are relevant for estimation
    + the size of the range of variation
    + the standard deviation of the $h_R$ estimates
    + the number of population pairs relevant for estimation
- if *n.edges*>3, an element named *nj.tree.eval* that gives for each evaluated rooted tree, the five f-statistics
configuration displaying the worst fit, i.e., with the five highest absolute Z-score for the predicted value
(obtained by internally calling the *compare.fitted.fstats* function). Note that these are independent of
the rooting (so cannot be used to infer the root position)

```R
scaf.tree<-rooted.njtree.builder(fstats=sim6p.readcount.fstats,
pop.sel=scaf.pops$pop.sets[1,],plot.nj=FALSE)
plot(scaf.tree$best.rooted.tree)
```

The resulting plot looks like this:

![Graph 3](./imgs/graph_3.png)

You can evaluate the Neighbor-Joining results and the $h_R$ statistics with the following code:

```R
scaf.tree$nj.tree.eval
scaf.tree$rot.het.est.var
```

You can obviously add leaves to the tree in the same way we saw before.

### 3. Extend a tree with a set of leaves

If we built our tree from scratch, there's a good chance that there is more than one population that was left out by our initial filtering: adding them manually with _add.leaf_ would then be inefficient, and that's why the _graph.builder_ class was implemented. You can now add more than one pool, for example, with the following code:

```R
# Build an initial 3 population trees with "Pool1","Pool3","Pool4" and "Pool5"
init.tree<-rooted.njtree.builder(fstats=sim6p.readcount.fstats,
pop.sel=c("Pool1","Pool3","Pool4","Pool5"),plot.nj=FALSE)
# Adding the three remaining pops
final.graphs<-graph.builder(x=init.tree$best.rooted.tree,leaves.to.add=c("Pool2","Pool6"),
fstats=sim6p.readcount.fstats)
# Plot the tree
plot(final.graph$best.fitted.graph)
```