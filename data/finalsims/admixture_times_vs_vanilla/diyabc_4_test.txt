 ############## MODEL CHOICE analysis using random forest ###############  

Name of the statobs file: statobsRF.txt 
Number of statobs in the file = 1 
Name of the reference table file: reftableRF.bin 
Name of the headerfile file: headerRF.txt 
Number of simulations loaded from the reference table = 40120 
Number of scenarios (i.e. models) in the reference table = 4 
Number of simulations available for each scenario from the loaded reference table = 10024 9984 10025 10087 
Number of parameters in the reference table = 13 15 15 15 
Number of summary statistics in the reference table (without LDA axes) = 292 
Number of simulations in the TRAINING DATASET used to built rf trees = 40000 
Number of trees in the forest = 1000 
Number of cores available =  128 
Number of cores used for computation = 126 
Analysis of each scenario independently (no grouping or selelection of scenarios) 
Number of ANALYSED scenarios (i.e. models) using RF = 4 
n.run = 10 

############################################################################################# 
--------------------> i.run = 1 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 26.0475%

Confusion matrix:
     1    2    3    4 class.error
1 9761   31   81  119  0.02311849
2   74 8172 1539  166  0.17877600
3  243 2286 4900 2563  0.50960769
4  419  393 2505 6748  0.32955787
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          469          150          222          159      0.747


############################################################################################# 
--------------------> i.run = 2 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 26.0725%

Confusion matrix:
     1    2    3    4 class.error
1 9763   34   80  115  0.02291833
2   71 8199 1539  142  0.17606271
3  246 2296 4882 2568  0.51140913
4  411  411 2516 6727  0.33164431
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          451          167          259          123      0.744


############################################################################################# 
--------------------> i.run = 3 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 26.03%

Confusion matrix:
     1    2    3    4 class.error
1 9763   33   74  122  0.02291833
2   69 8196 1541  145  0.17636418
3  247 2283 4917 2545  0.50790633
4  418  407 2528 6712  0.33313462
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          451          187          219          143      0.736


############################################################################################# 
--------------------> i.run = 4 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 26.0575%

Confusion matrix:
     1    2    3    4 class.error
1 9766   28   84  114  0.02261809
2   66 8187 1546  152  0.17726862
3  246 2296 4898 2552  0.50980785
4  406  415 2518 6726  0.33174367
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          481          179          218          122      0.694


############################################################################################# 
--------------------> i.run = 5 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 25.97%

Confusion matrix:
     1    2    3    4 class.error
1 9763   31   82  116  0.02291833
2   73 8165 1573  140  0.17947945
3  250 2262 4951 2529  0.50450360
4  415  386 2531 6733  0.33104819
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          464          174          232          130      0.737


############################################################################################# 
--------------------> i.run = 6 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 26.07%

Confusion matrix:
     1    2    3    4 class.error
1 9778   30   75  109  0.02141713
2   77 8164 1556  154  0.17957994
3  249 2260 4910 2573  0.50860689
4  422  395 2528 6720  0.33233979
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          462          152          246          140       0.73


############################################################################################# 
--------------------> i.run = 7 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 26.06%

Confusion matrix:
     1    2    3    4 class.error
1 9767   28   77  120  0.02251801
2   65 8188 1550  148  0.17716812
3  243 2315 4898 2536  0.50980785
4  414  395 2533 6723  0.33204173
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          451          152          267          130      0.724


############################################################################################# 
--------------------> i.run = 8 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 25.9575%

Confusion matrix:
     1    2    3    4 class.error
1 9759   29   78  126  0.02331865
2   76 8187 1553  135  0.17726862
3  257 2266 4956 2513  0.50400320
4  415  401 2534 6715  0.33283656
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          450          196          235          119      0.739


############################################################################################# 
--------------------> i.run = 9 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 25.905%

Confusion matrix:
     1    2    3    4 class.error
1 9764   29   84  115  0.02281825
2   73 8164 1565  149  0.17957994
3  246 2271 4952 2523  0.50440352
4  418  387 2502 6758  0.32856433
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          481          174          204          141       0.76


############################################################################################# 
--------------------> i.run = 10 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 40000
Out-of-bag prior error rate: 25.8925%

Confusion matrix:
     1    2    3    4 class.error
1 9768   30   75  119  0.02241793
2   72 8194 1544  141  0.17656517
3  245 2272 4939 2536  0.50570456
4  418  399 2506 6742  0.33015400
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 votes model3 votes model4 post.proba
              1          457          165          231          147      0.737



############################################################################################# 
############################################################################################# 
ABSTRACT over the n.run for each vector of STATOBS 
############################################################################################# 
############################################################################################# 

Recalling what are the different statobs lines 
Statobs_1 =     ML1p_1        ML1p_2        ML1p_3        ML1p_4        ML1p_5       ML2p_1.2      ML2p_1.3      ML2p_1.4      ML2p_1.5      ML2p_2.3      ML2p_2.4      ML2p_2.5      ML2p_3.4      ML2p_3.5      ML2p_4.5     ML3p_1.2.3    ML3p_1.2.4    ML3p_1.2.5    ML3p_1.3.4    ML3p_1.3.5    ML3p_1.4.5    ML3p_2.3.4    ML3p_2.3.5    ML3p_2.4.5    ML3p_3.4.5   ML4p_1.2.3.4  ML4p_1.2.3.5  ML4p_1.2.4.5  ML4p_1.3.4.5  ML4p_2.3.4.5     HWm_1         HWm_2         HWm_3         HWm_4         HWm_5         HWv_1         HWv_2         HWv_3         HWv_4         HWv_5        HBm_1.2       HBm_1.3       HBm_1.4       HBm_1.5       HBm_2.3       HBm_2.4       HBm_2.5       HBm_3.4       HBm_3.5       HBm_4.5       HBv_1.2       HBv_1.3       HBv_1.4       HBv_1.5       HBv_2.3       HBv_2.4       HBv_2.5       HBv_3.4       HBv_3.5       HBv_4.5       FST1m_1       FST1m_2       FST1m_3       FST1m_4       FST1m_5       FST1v_1       FST1v_2       FST1v_3       FST1v_4       FST1v_5      FST2m_1.2     FST2m_1.3     FST2m_1.4     FST2m_1.5     FST2m_2.3     FST2m_2.4     FST2m_2.5     FST2m_3.4     FST2m_3.5     FST2m_4.5     FST2v_1.2     FST2v_1.3     FST2v_1.4     FST2v_1.5     FST2v_2.3     FST2v_2.4     FST2v_2.5     FST2v_3.4     FST2v_3.5     FST2v_4.5      NEIm_1.2      NEIm_1.3      NEIm_1.4      NEIm_1.5      NEIm_2.3      NEIm_2.4      NEIm_2.5      NEIm_3.4      NEIm_3.5      NEIm_4.5      NEIv_1.2      NEIv_1.3      NEIv_1.4      NEIv_1.5      NEIv_2.3      NEIv_2.4      NEIv_2.5      NEIv_3.4      NEIv_3.5      NEIv_4.5     AMLm_1.2.3    AMLm_2.1.3    AMLm_3.1.2    AMLm_1.2.4    AMLm_2.1.4    AMLm_4.1.2    AMLm_1.2.5    AMLm_2.1.5    AMLm_5.1.2    AMLm_1.3.4    AMLm_3.1.4    AMLm_4.1.3    AMLm_1.3.5    AMLm_3.1.5    AMLm_5.1.3    AMLm_1.4.5    AMLm_4.1.5    AMLm_5.1.4    AMLm_2.3.4    AMLm_3.2.4    AMLm_4.2.3    AMLm_2.3.5    AMLm_3.2.5    AMLm_5.2.3    AMLm_2.4.5    AMLm_4.2.5    AMLm_5.2.4    AMLm_3.4.5    AMLm_4.3.5    AMLm_5.3.4    AMLv_1.2.3    AMLv_2.1.3    AMLv_3.1.2    AMLv_1.2.4    AMLv_2.1.4    AMLv_4.1.2    AMLv_1.2.5    AMLv_2.1.5    AMLv_5.1.2    AMLv_1.3.4    AMLv_3.1.4    AMLv_4.1.3    AMLv_1.3.5    AMLv_3.1.5    AMLv_5.1.3    AMLv_1.4.5    AMLv_4.1.5    AMLv_5.1.4    AMLv_2.3.4    AMLv_3.2.4    AMLv_4.2.3    AMLv_2.3.5    AMLv_3.2.5    AMLv_5.2.3    AMLv_2.4.5    AMLv_4.2.5    AMLv_5.2.4    AMLv_3.4.5    AMLv_4.3.5    AMLv_5.3.4   FST3m_1.2.3   FST3m_1.2.4   FST3m_1.2.5   FST3m_1.3.4   FST3m_1.3.5   FST3m_1.4.5   FST3m_2.3.4   FST3m_2.3.5   FST3m_2.4.5   FST3m_3.4.5   FST3v_1.2.3   FST3v_1.2.4   FST3v_1.2.5   FST3v_1.3.4   FST3v_1.3.5   FST3v_1.4.5   FST3v_2.3.4   FST3v_2.3.5   FST3v_2.4.5   FST3v_3.4.5   FST4m_1.2.3.4  FST4m_1.2.3.5  FST4m_1.2.4.5  FST4m_1.3.4.5  FST4m_2.3.4.5  FST4v_1.2.3.4  FST4v_1.2.3.5  FST4v_1.2.4.5  FST4v_1.3.4.5  FST4v_2.3.4.5    FSTGm_0       FSTGv_0      F3m_1.2.3     F3m_2.1.3     F3m_3.1.2     F3m_1.2.4     F3m_2.1.4     F3m_4.1.2     F3m_1.2.5     F3m_2.1.5     F3m_5.1.2     F3m_1.3.4     F3m_3.1.4     F3m_4.1.3     F3m_1.3.5     F3m_3.1.5     F3m_5.1.3     F3m_1.4.5     F3m_4.1.5     F3m_5.1.4     F3m_2.3.4     F3m_3.2.4     F3m_4.2.3     F3m_2.3.5     F3m_3.2.5     F3m_5.2.3     F3m_2.4.5     F3m_4.2.5     F3m_5.2.4     F3m_3.4.5     F3m_4.3.5     F3m_5.3.4     F3v_1.2.3     F3v_2.1.3     F3v_3.1.2     F3v_1.2.4     F3v_2.1.4     F3v_4.1.2     F3v_1.2.5     F3v_2.1.5     F3v_5.1.2     F3v_1.3.4     F3v_3.1.4     F3v_4.1.3     F3v_1.3.5     F3v_3.1.5     F3v_5.1.3     F3v_1.4.5     F3v_4.1.5     F3v_5.1.4     F3v_2.3.4     F3v_3.2.4     F3v_4.2.3     F3v_2.3.5     F3v_3.2.5     F3v_5.2.3     F3v_2.4.5     F3v_4.2.5     F3v_5.2.4     F3v_3.4.5     F3v_4.3.5     F3v_5.3.4    F4m_1.2.3.4   F4m_1.3.2.4   F4m_1.4.2.3   F4m_1.2.3.5   F4m_1.3.2.5   F4m_1.5.2.3   F4m_1.2.4.5   F4m_1.4.2.5   F4m_1.5.2.4   F4m_1.3.4.5   F4m_1.4.3.5   F4m_1.5.3.4   F4m_2.3.4.5   F4m_2.4.3.5   F4m_2.5.3.4   F4v_1.2.3.4   F4v_1.3.2.4   F4v_1.4.2.3   F4v_1.2.3.5   F4v_1.3.2.5   F4v_1.5.2.3   F4v_1.2.4.5   F4v_1.4.2.5   F4v_1.5.2.4   F4v_1.3.4.5   F4v_1.4.3.5   F4v_1.5.3.4   F4v_2.3.4.5   F4v_2.4.3.5   F4v_2.5.3.4  

Summary for Statobs = 1 
       S1              S2              S3              S4       
 Min.   :450.0   Min.   :150.0   Min.   :204.0   Min.   :119.0  
 1st Qu.:451.0   1st Qu.:155.2   1st Qu.:219.8   1st Qu.:124.8  
 Median :459.5   Median :170.5   Median :231.5   Median :135.0  
 Mean   :461.7   Mean   :169.6   Mean   :233.3   Mean   :135.4  
 3rd Qu.:467.8   3rd Qu.:177.8   3rd Qu.:243.2   3rd Qu.:142.5  
 Max.   :481.0   Max.   :196.0   Max.   :267.0   Max.   :159.0  
      Prob             Win     Prior_error    
 Min.   :0.6940   Min.   :1   Min.   :0.2589  
 1st Qu.:0.7315   1st Qu.:1   1st Qu.:0.2596  
 Median :0.7370   Median :1   Median :0.2604  
 Mean   :0.7348   Mean   :1   Mean   :0.2601  
 3rd Qu.:0.7428   3rd Qu.:1   3rd Qu.:0.2606  
 Max.   :0.7600   Max.   :1   Max.   :0.2607  



Winner scenarios for Statobs = 1 
 [1] 1 1 1 1 1 1 1 1 1 1



  Win.Scen.ID occur
1           1    10

Mean vote numbers for each statobs 

Statobs # 1 
  Scenario Mean.Votes
1        1      461.7
2        2      169.6
3        3      233.3
4        4      135.4


Final results without threshold:
Global mean number of votes over all statobs:
  Scenario Mean.Votes
1        1      461.7
2        2      169.6
3        3      233.3
4        4      135.4

### End of Results ###
############################################################################################# 
############################################################################################# 
########### OTHER PRESENTATION OF FINAL RESULTS WITHOUT ANY THRESHOLD ###################### 
############################################################################################# 
############################################################################################# 

DataFrame for mean number of votes with TotalTrees row 
    Scenario Statobs1
1          1    461.7
2          2    169.6
3          3    233.3
4          4    135.4
5 TotalTrees   1000.0
nDataFrame for mean fraction of votes with Total% row 
       Scenario Statobs1
1             1   0.4617
2             2   0.1696
3             3   0.2333
4             4   0.1354
5 TotalFraction   1.0000

### End of Results ###
############################################################################################# 
############################################################################################# 
########### OTHER PRESENTATION OF FINAL RESULTS USING A DEFINED THRESHOLD          ########## 
############################################################################################# 
############################################################################################# 
ntree = 1000 
results_threshold_fraction_trees= 0.05 
threshold in min number of trees = 50 

Sub-dataframe for the scenarios with mean number of votes >  50 
  Scenario Statobs1
1        1    461.7
2        2    169.6
3        3    233.3
4        4    135.4

Sub-dataframe for the scenarios with mean fraction of votes >  0.05 
  Scenario Statobs1
1        1   0.4617
2        2   0.1696
3        3   0.2333
4        4   0.1354

Sum of the nbre of votes for scenario relaining after threshold 
           Column  Sum
Statobs1 Statobs1 1000

Sum of the nbre of votes for scenario relaining after threshold 
           Column Sum
Statobs1 Statobs1   1
############################################################################################# 
Drawing figures for the last of the i.run = 10 
############################################################################################# 
Press <ENTER> to Continue
THREE ILLUSTRATIVE GRAPHICS have been produced and saved in three different files: FALSEFile named prior_errors_vs_number_of_trees.png: Graphic providing prior error rates for forests with different number of trees and computed using an Out-of-Bag procedure, e.g. Fig. 3 in Pudlo et al. 2016 
File named graph_lda.pdf = LDA projections of the reference table for the different scenarios plus the observed dataset cf. black star in the figure 
File name graph_varImpPlot.pdf = the contributions of the 30 most important statistics to the RF (e.g. Fig. S6 and Fig. S7 in Pudlo et al. 2016) 
