 ############## MODEL CHOICE analysis using random forest ###############  

Name of the statobs file: statobsRF.txt 
Number of statobs in the file = 1 
Name of the reference table file: reftableRF.bin 
Name of the headerfile file: headerRF.txt 
Number of simulations loaded from the reference table = 12000 
Number of scenarios (i.e. models) in the reference table = 2 
Number of simulations available for each scenario from the loaded reference table = 5950 6050 
Number of parameters in the reference table = 13 13 
Number of summary statistics in the reference table (without LDA axes) = 292 
Number of simulations in the TRAINING DATASET used to built rf trees = 12000 
Number of trees in the forest = 1000 
Number of cores available =  128 
Number of cores used for computation = 126 
Analysis of each scenario independently (no grouping or selelection of scenarios) 
Number of ANALYSED scenarios (i.e. models) using RF = 2 
n.run = 10 

############################################################################################# 
--------------------> i.run = 1 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.3417%

Confusion matrix:
     1    2 class.error
1 4100 1850   0.3109244
2 1791 4259   0.2960331
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          525          475      0.834


############################################################################################# 
--------------------> i.run = 2 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.9583%

Confusion matrix:
     1    2 class.error
1 4055 1895   0.3184874
2 1820 4230   0.3008264
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          521          479      0.772


############################################################################################# 
--------------------> i.run = 3 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.375%

Confusion matrix:
     1    2 class.error
1 4072 1878   0.3156303
2 1767 4283   0.2920661
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          513          487      0.812


############################################################################################# 
--------------------> i.run = 4 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.45%

Confusion matrix:
     1    2 class.error
1 4103 1847   0.3104202
2 1807 4243   0.2986777
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          507          493      0.825


############################################################################################# 
--------------------> i.run = 5 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.425%

Confusion matrix:
     1    2 class.error
1 4103 1847   0.3104202
2 1804 4246   0.2981818
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          518          482      0.802


############################################################################################# 
--------------------> i.run = 6 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.5333%

Confusion matrix:
     1    2 class.error
1 4082 1868   0.3139496
2 1796 4254   0.2968595
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              2          483          517      0.814


############################################################################################# 
--------------------> i.run = 7 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.2583%

Confusion matrix:
     1    2 class.error
1 4118 1832   0.3078992
2 1799 4251   0.2973554
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              2          498          502      0.826


############################################################################################# 
--------------------> i.run = 8 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.45%

Confusion matrix:
     1    2 class.error
1 4100 1850   0.3109244
2 1804 4246   0.2981818
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          508          492      0.807


############################################################################################# 
--------------------> i.run = 9 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.45%

Confusion matrix:
     1    2 class.error
1 4103 1847   0.3104202
2 1807 4243   0.2986777
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          507          493       0.81


############################################################################################# 
--------------------> i.run = 10 


RF TRAINING step using all scenarios separately 

PRIOR ERROR RATES (using the Out-of-Bag statistical procedure): we provide mean Out-of-Bag prior error rate and matrix of errors with the true scenario number as rows and the chosen scenarios as columns 

Call:
 abcrf(formula = scenario ~ ., data = dataTrain, lda = TRUE, ntree = ntree, paral = TRUE, ncores = how.many.cores.used.for.computation, min.node.size = 1, save.memory = FALSE) 
includes the axes of a preliminary LDA

Number of simulations: 12000
Out-of-bag prior error rate: 30.525%

Confusion matrix:
     1    2 class.error
1 4075 1875   0.3151261
2 1788 4262   0.2955372
Numerical values of Importance Measures of the summary statistics (i.e. explanatory variables) are stored in the file named importance_measures_of_summary statistics_SORTED.txt 

RF MODEL CHOICE PREDICTION on the observed dataset(s): we provide the index of the selected model (i.e. scenario), the votes for each model (over the total number of trees in the forest) and the posterior probability for the selected model 
 selected model votes model1 votes model2 post.proba
              1          507          493      0.811



############################################################################################# 
############################################################################################# 
ABSTRACT over the n.run for each vector of STATOBS 
############################################################################################# 
############################################################################################# 

Recalling what are the different statobs lines 
Statobs_1 =     ML1p_1        ML1p_2        ML1p_3        ML1p_4        ML1p_5       ML2p_1.2      ML2p_1.3      ML2p_1.4      ML2p_1.5      ML2p_2.3      ML2p_2.4      ML2p_2.5      ML2p_3.4      ML2p_3.5      ML2p_4.5     ML3p_1.2.3    ML3p_1.2.4    ML3p_1.2.5    ML3p_1.3.4    ML3p_1.3.5    ML3p_1.4.5    ML3p_2.3.4    ML3p_2.3.5    ML3p_2.4.5    ML3p_3.4.5   ML4p_1.2.3.4  ML4p_1.2.3.5  ML4p_1.2.4.5  ML4p_1.3.4.5  ML4p_2.3.4.5     HWm_1         HWm_2         HWm_3         HWm_4         HWm_5         HWv_1         HWv_2         HWv_3         HWv_4         HWv_5        HBm_1.2       HBm_1.3       HBm_1.4       HBm_1.5       HBm_2.3       HBm_2.4       HBm_2.5       HBm_3.4       HBm_3.5       HBm_4.5       HBv_1.2       HBv_1.3       HBv_1.4       HBv_1.5       HBv_2.3       HBv_2.4       HBv_2.5       HBv_3.4       HBv_3.5       HBv_4.5       FST1m_1       FST1m_2       FST1m_3       FST1m_4       FST1m_5       FST1v_1       FST1v_2       FST1v_3       FST1v_4       FST1v_5      FST2m_1.2     FST2m_1.3     FST2m_1.4     FST2m_1.5     FST2m_2.3     FST2m_2.4     FST2m_2.5     FST2m_3.4     FST2m_3.5     FST2m_4.5     FST2v_1.2     FST2v_1.3     FST2v_1.4     FST2v_1.5     FST2v_2.3     FST2v_2.4     FST2v_2.5     FST2v_3.4     FST2v_3.5     FST2v_4.5      NEIm_1.2      NEIm_1.3      NEIm_1.4      NEIm_1.5      NEIm_2.3      NEIm_2.4      NEIm_2.5      NEIm_3.4      NEIm_3.5      NEIm_4.5      NEIv_1.2      NEIv_1.3      NEIv_1.4      NEIv_1.5      NEIv_2.3      NEIv_2.4      NEIv_2.5      NEIv_3.4      NEIv_3.5      NEIv_4.5     AMLm_1.2.3    AMLm_2.1.3    AMLm_3.1.2    AMLm_1.2.4    AMLm_2.1.4    AMLm_4.1.2    AMLm_1.2.5    AMLm_2.1.5    AMLm_5.1.2    AMLm_1.3.4    AMLm_3.1.4    AMLm_4.1.3    AMLm_1.3.5    AMLm_3.1.5    AMLm_5.1.3    AMLm_1.4.5    AMLm_4.1.5    AMLm_5.1.4    AMLm_2.3.4    AMLm_3.2.4    AMLm_4.2.3    AMLm_2.3.5    AMLm_3.2.5    AMLm_5.2.3    AMLm_2.4.5    AMLm_4.2.5    AMLm_5.2.4    AMLm_3.4.5    AMLm_4.3.5    AMLm_5.3.4    AMLv_1.2.3    AMLv_2.1.3    AMLv_3.1.2    AMLv_1.2.4    AMLv_2.1.4    AMLv_4.1.2    AMLv_1.2.5    AMLv_2.1.5    AMLv_5.1.2    AMLv_1.3.4    AMLv_3.1.4    AMLv_4.1.3    AMLv_1.3.5    AMLv_3.1.5    AMLv_5.1.3    AMLv_1.4.5    AMLv_4.1.5    AMLv_5.1.4    AMLv_2.3.4    AMLv_3.2.4    AMLv_4.2.3    AMLv_2.3.5    AMLv_3.2.5    AMLv_5.2.3    AMLv_2.4.5    AMLv_4.2.5    AMLv_5.2.4    AMLv_3.4.5    AMLv_4.3.5    AMLv_5.3.4   FST3m_1.2.3   FST3m_1.2.4   FST3m_1.2.5   FST3m_1.3.4   FST3m_1.3.5   FST3m_1.4.5   FST3m_2.3.4   FST3m_2.3.5   FST3m_2.4.5   FST3m_3.4.5   FST3v_1.2.3   FST3v_1.2.4   FST3v_1.2.5   FST3v_1.3.4   FST3v_1.3.5   FST3v_1.4.5   FST3v_2.3.4   FST3v_2.3.5   FST3v_2.4.5   FST3v_3.4.5   FST4m_1.2.3.4  FST4m_1.2.3.5  FST4m_1.2.4.5  FST4m_1.3.4.5  FST4m_2.3.4.5  FST4v_1.2.3.4  FST4v_1.2.3.5  FST4v_1.2.4.5  FST4v_1.3.4.5  FST4v_2.3.4.5    FSTGm_0       FSTGv_0      F3m_1.2.3     F3m_2.1.3     F3m_3.1.2     F3m_1.2.4     F3m_2.1.4     F3m_4.1.2     F3m_1.2.5     F3m_2.1.5     F3m_5.1.2     F3m_1.3.4     F3m_3.1.4     F3m_4.1.3     F3m_1.3.5     F3m_3.1.5     F3m_5.1.3     F3m_1.4.5     F3m_4.1.5     F3m_5.1.4     F3m_2.3.4     F3m_3.2.4     F3m_4.2.3     F3m_2.3.5     F3m_3.2.5     F3m_5.2.3     F3m_2.4.5     F3m_4.2.5     F3m_5.2.4     F3m_3.4.5     F3m_4.3.5     F3m_5.3.4     F3v_1.2.3     F3v_2.1.3     F3v_3.1.2     F3v_1.2.4     F3v_2.1.4     F3v_4.1.2     F3v_1.2.5     F3v_2.1.5     F3v_5.1.2     F3v_1.3.4     F3v_3.1.4     F3v_4.1.3     F3v_1.3.5     F3v_3.1.5     F3v_5.1.3     F3v_1.4.5     F3v_4.1.5     F3v_5.1.4     F3v_2.3.4     F3v_3.2.4     F3v_4.2.3     F3v_2.3.5     F3v_3.2.5     F3v_5.2.3     F3v_2.4.5     F3v_4.2.5     F3v_5.2.4     F3v_3.4.5     F3v_4.3.5     F3v_5.3.4    F4m_1.2.3.4   F4m_1.3.2.4   F4m_1.4.2.3   F4m_1.2.3.5   F4m_1.3.2.5   F4m_1.5.2.3   F4m_1.2.4.5   F4m_1.4.2.5   F4m_1.5.2.4   F4m_1.3.4.5   F4m_1.4.3.5   F4m_1.5.3.4   F4m_2.3.4.5   F4m_2.4.3.5   F4m_2.5.3.4   F4v_1.2.3.4   F4v_1.3.2.4   F4v_1.4.2.3   F4v_1.2.3.5   F4v_1.3.2.5   F4v_1.5.2.3   F4v_1.2.4.5   F4v_1.4.2.5   F4v_1.5.2.4   F4v_1.3.4.5   F4v_1.4.3.5   F4v_1.5.3.4   F4v_2.3.4.5   F4v_2.4.3.5   F4v_2.5.3.4  

Summary for Statobs = 1 
       S1              S2             Prob             Win     
 Min.   :483.0   Min.   :475.0   Min.   :0.7720   Min.   :1.0  
 1st Qu.:507.0   1st Qu.:483.2   1st Qu.:0.8077   1st Qu.:1.0  
 Median :507.5   Median :492.5   Median :0.8115   Median :1.0  
 Mean   :508.7   Mean   :491.3   Mean   :0.8113   Mean   :1.2  
 3rd Qu.:516.8   3rd Qu.:493.0   3rd Qu.:0.8223   3rd Qu.:1.0  
 Max.   :525.0   Max.   :517.0   Max.   :0.8340   Max.   :2.0  
  Prior_error    
 Min.   :0.3026  
 1st Qu.:0.3039  
 Median :0.3045  
 Mean   :0.3048  
 3rd Qu.:0.3051  
 Max.   :0.3096  



Winner scenarios for Statobs = 1 
 [1] 1 1 1 1 1 2 2 1 1 1



  Win.Scen.ID occur
1           1     8
2           2     2

Mean vote numbers for each statobs 

Statobs # 1 
  Scenario Mean.Votes
1        1      508.7
2        2      491.3


Final results without threshold:
Global mean number of votes over all statobs:
  Scenario Mean.Votes
1        1      508.7
2        2      491.3

### End of Results ###
############################################################################################# 
############################################################################################# 
########### OTHER PRESENTATION OF FINAL RESULTS WITHOUT ANY THRESHOLD ###################### 
############################################################################################# 
############################################################################################# 

DataFrame for mean number of votes with TotalTrees row 
    Scenario Statobs1
1          1    508.7
2          2    491.3
3 TotalTrees   1000.0
nDataFrame for mean fraction of votes with Total% row 
       Scenario Statobs1
1             1   0.5087
2             2   0.4913
3 TotalFraction   1.0000

### End of Results ###
############################################################################################# 
############################################################################################# 
########### OTHER PRESENTATION OF FINAL RESULTS USING A DEFINED THRESHOLD          ########## 
############################################################################################# 
############################################################################################# 
ntree = 1000 
results_threshold_fraction_trees= 0.05 
threshold in min number of trees = 50 

Sub-dataframe for the scenarios with mean number of votes >  50 
  Scenario Statobs1
1        1    508.7
2        2    491.3

Sub-dataframe for the scenarios with mean fraction of votes >  0.05 
  Scenario Statobs1
1        1   0.5087
2        2   0.4913

Sum of the nbre of votes for scenario relaining after threshold 
           Column  Sum
Statobs1 Statobs1 1000

Sum of the nbre of votes for scenario relaining after threshold 
           Column Sum
Statobs1 Statobs1   1
############################################################################################# 
Drawing figures for the last of the i.run = 10 
############################################################################################# 
Press <ENTER> to Continue
THREE ILLUSTRATIVE GRAPHICS have been produced and saved in three different files: FALSEFile named prior_errors_vs_number_of_trees.png: Graphic providing prior error rates for forests with different number of trees and computed using an Out-of-Bag procedure, e.g. Fig. 3 in Pudlo et al. 2016 
File named graph_lda.pdf = LDA projections of the reference table for the different scenarios plus the observed dataset cf. black star in the figure 
File name graph_varImpPlot.pdf = the contributions of the 30 most important statistics to the RF (e.g. Fig. S6 and Fig. S7 in Pudlo et al. 2016) 
